{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5050380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {align:left;display:block} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "table_css = 'table {align:left;display:block} '\n",
    "HTML('<style>{}</style>'.format(table_css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80316706",
   "metadata": {},
   "source": [
    "# 9/8/2022\n",
    "\n",
    "### Pameters and Hyperparameters\n",
    "- model parameters are estimated from data automatically\n",
    "- hyperparameters are set manually before training the model\n",
    "    - optimized after training\n",
    "    \n",
    "### Parametric Vs. Nonparametric models\n",
    "\n",
    "##### Parametric\n",
    "- f(x) is assumed\n",
    "    - examples: linear, GLM, logistic regression\n",
    "|Pros|Cons|\n",
    "|:-|:-|\n",
    "|Simpler|Limited complexity|\n",
    "|Faster| |\n",
    "|Less Data| |\n",
    "\n",
    "##### Non-Parametric\n",
    "- f(x) is not assumed, free to learn any functional form\n",
    "    - examples: KNN, CART, Random forest, SVM\n",
    "|Pros|Cons|\n",
    "|:-|:-|\n",
    "|Flexibility|Slower|\n",
    "|Performance|More data |\n",
    "|| Overfitting|\n",
    "\n",
    "- Key take away: Parametric is less flexible, Non is more flexible\n",
    "\n",
    "### Evaulation metric\n",
    "- In general, we want to compare how close the predicitons are to the actual numbers in the test set\n",
    "- We typically assess this using: \n",
    "    - MSE for quantitative\n",
    "    - Misclassification rate for qualitative\n",
    "\n",
    "##### Regresion\n",
    "- variable is continous \n",
    "    - classied as e hat, residuals -> (y - Å·)\n",
    "\n",
    "## Bias Variance Trade Off\n",
    "\n",
    "##### What is bias? \n",
    "- On average, we are not hitting our target\n",
    "- Target is the true relationship in the data\n",
    "- The more simple the model, the higher the bias\n",
    "\n",
    "##### What is variance?\n",
    "- How different are different realizations of the same model\n",
    "- For a simple model, the variance is low\n",
    "\n",
    "### MSE decomposition\n",
    "\n",
    "MSE = model variance + model bias + irreducible error\n",
    "\n",
    "- The goal is to minimize the sum of model variance and model bias\n",
    "- this is bias-variance tradeoff, reducing one often leads to the increase of the other \n",
    "\n",
    "### Overfitting\n",
    "- Happens when the fitted algorithm does not generalize well to the new data\n",
    "    - We don't want to memorize the data, we want to learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a18afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6caba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
