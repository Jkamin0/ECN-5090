{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5050380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {align:left;display:block} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "table_css = 'table {align:left;display:block} '\n",
    "HTML('<style>{}</style>'.format(table_css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80316706",
   "metadata": {},
   "source": [
    "# 9/8/2022\n",
    "\n",
    "### Pameters and Hyperparameters\n",
    "- model parameters are estimated from data automatically\n",
    "- hyperparameters are set manually before training the model\n",
    "    - optimized after training\n",
    "    \n",
    "### Parametric Vs. Nonparametric models\n",
    "\n",
    "##### Parametric\n",
    "- f(x) is assumed\n",
    "    - examples: linear, GLM, logistic regression\n",
    "|Pros|Cons|\n",
    "|:-|:-|\n",
    "|Simpler|Limited complexity|\n",
    "|Faster| |\n",
    "|Less Data| |\n",
    "\n",
    "##### Non-Parametric\n",
    "- f(x) is not assumed, free to learn any functional form\n",
    "    - examples: KNN, CART, Random forest, SVM\n",
    "|Pros|Cons|\n",
    "|:-|:-|\n",
    "|Flexibility|Slower|\n",
    "|Performance|More data |\n",
    "|| Overfitting|\n",
    "\n",
    "- Key take away: Parametric is less flexible, Non is more flexible\n",
    "\n",
    "### Evaulation metric\n",
    "- In general, we want to compare how close the predicitons are to the actual numbers in the test set\n",
    "- We typically assess this using: \n",
    "    - MSE for quantitative\n",
    "    - Misclassification rate for qualitative\n",
    "\n",
    "##### Regresion\n",
    "- variable is continous \n",
    "    - classied as e hat, residuals -> (y - Å·)\n",
    "\n",
    "## Bias Variance Trade Off\n",
    "\n",
    "##### What is bias? \n",
    "- On average, we are not hitting our target\n",
    "- Target is the true relationship in the data\n",
    "- The more simple the model, the higher the bias\n",
    "\n",
    "##### What is variance?\n",
    "- How different are different realizations of the same model\n",
    "- For a simple model, the variance is low\n",
    "\n",
    "### MSE decomposition\n",
    "\n",
    "MSE = model variance + model bias + irreducible error\n",
    "\n",
    "- The goal is to minimize the sum of model variance and model bias\n",
    "- this is bias-variance tradeoff, reducing one often leads to the increase of the other \n",
    "\n",
    "### Overfitting\n",
    "- Happens when the fitted algorithm does not generalize well to the new data\n",
    "    - We don't want to memorize the data, we want to learn from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511247e3",
   "metadata": {},
   "source": [
    "# Class 5 9/13\n",
    "\n",
    "## Resampling Methods\n",
    "\n",
    "### Partitioning of the data\n",
    "1. Training set - 60%\n",
    "2. Validation set - 20%\n",
    "3. Test set (holdout set) - 20% \n",
    "- To be valid and useful, any supervised machine learning model must generalize well\n",
    "    - Must apply well to the test set, outside of the training\n",
    "\n",
    "### Resampling methods\n",
    "- sometimes the dataset is too small to split up into multiple groups\n",
    "- To help solve this wel combine the training and validation sets\n",
    "    - Combination refered to as the training set\n",
    "    \n",
    "### K-fold Cross Validation \n",
    "- Split model into even parts\n",
    "- Swap out 1 part to be the test, while the rest remain as training\n",
    "    - Repeate this process through, alternating the test section until all have rotated \n",
    "    \n",
    "### Time Series Cross Validation\n",
    "- Shuffling the data is not an option \n",
    "- Expanding windows -> start with smaller portion, increase each iteration\n",
    "- Rolling windows -> use last 12 months to predict the next\n",
    "\n",
    "### Why do we use Cross Validation? \n",
    "1. Model selection\n",
    "2. Fair esitame of the performance of the model in the test set\n",
    "- After selecting the best model, we esitmate the generalization error using the test set\n",
    "\n",
    "\n",
    "## Solvers (Gradient Descent)\n",
    "\n",
    "### Cost Function\n",
    "- Cost function tells us how good our model is at making predictions for a given set of parameters\n",
    "    - Want to minimize this\n",
    "    \n",
    "### Gradient Descent\n",
    "- an iterative optimization algorithm for finding the minumum of a function\n",
    " sample change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
